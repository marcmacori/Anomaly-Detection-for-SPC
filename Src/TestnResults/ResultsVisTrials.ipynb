{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from sklearn.metrics import (confusion_matrix, precision_recall_curve, average_precision_score,\n",
    "                             precision_score,recall_score, classification_report, f1_score)\n",
    "import joblib\n",
    "import os\n",
    "os.chdir(r'C:/Users/Marc/Desktop/TFG/R Files/Anomaly Detection for SPC')\n",
    "from Src.FeatureExt.ML_AD_Preprocessing import *\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from plotly import graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "#import data and ML Modelss\n",
    "TS1 = pd.read_csv(\"Data/TimeSeries1.csv\", index_col = 0)\n",
    "TS1 = TS1.iloc[1280:1600, :]\n",
    "TS1_Class = pd.read_csv(\"Data/TimeSeries1_Classification.csv\", index_col = 0)\n",
    "TS1_Class = TS1_Class.iloc[1280:1600, 19:60]\n",
    "TS1_Class = np.array(TS1_Class).reshape(TS1_Class.size)\n",
    "\n",
    "TS1_WE_Class = pd.read_csv(\"Data/TimeSeries1_WE_Classification.csv\", index_col = 0)\n",
    "TS1_WE_Class = np.array(TS1_WE_Class.iloc[1280:1600])\\\n",
    "    .reshape(TS1_WE_Class.iloc[1280:1600].size)\n",
    "\n",
    "TS1_Nelson_Class = pd.read_csv(\"Data/TimeSeries1_Nelson_Classification.csv\", index_col = 0)\n",
    "TS1_Nelson_Class = np.array(TS1_Nelson_Class.iloc[1280:1600])\\\n",
    "    .reshape(TS1_Nelson_Class.iloc[1280:1600].size)\n",
    "\n",
    "iforest = joblib.load('ML_Models/ML_iforest.sav')\n",
    "\n",
    "SVM = joblib.load('ML_Models/ML_SVM.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pre-processing\n",
    "#Standardize data based on first 20 points of chart, which is supposed in control       \n",
    "X_train = stdvector(TS1)\n",
    "\n",
    "#Extract features\n",
    "X_test = sw_dataset_3(X_train, 20)\n",
    "X_test = np.transpose(X_test)\n",
    "scaler = StandardScaler()\n",
    "scaler = scaler.fit(X_test)\n",
    "X_test = pd.DataFrame(X_test,\\\n",
    "     columns = [\"last_value\", \"mean20\", \"sigma20\",\"mean5\", \"sigma5\", \"find_if\", \"kurtosis\",\n",
    "     \"dir_change\", 'wavg', 'slope', 'meancross', 'rdist', 'brange'])\n",
    "X_test_SVM = scaler.transform(X_test)\n",
    "X_test_SVM = pd.DataFrame(X_test_SVM, columns = [\"last_value\", \"mean20\", \"sigma20\",\"mean5\", \"sigma5\", \"find_if\", \"kurtosis\",\n",
    "     \"dir_change\", 'wavg', 'slope', 'meancross', 'rdist', 'brange'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict from ML Modelss\n",
    "#Predict iForest\n",
    "predictions_forest = iforest.predict(np.array(X_test))\n",
    "predictions_forest = np.array((predictions_forest == -1)*1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict SVM\n",
    "predictions_SVM = SVM.predict(np.array(X_test_SVM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion Matrices Global\n",
    "cm_WE = confusion_matrix(TS1_Class, TS1_WE_Class)\n",
    "cm_Nelson = confusion_matrix(TS1_Class, TS1_Nelson_Class)\n",
    "cm_forest = confusion_matrix(TS1_Class, predictions_forest)\n",
    "cm_SVM = confusion_matrix(TS1_Class, predictions_SVM)\n",
    "\n",
    "#Confusion Matrices per error type\n",
    "TS1_Class_Normal = TS1_Class[0:1640]\n",
    "TS1_Class_Cyclic = TS1_Class[1640:3280]\n",
    "TS1_Class_Systematic = TS1_Class[3280:4920]\n",
    "TS1_Class_Stratified = TS1_Class[4920:6560]\n",
    "TS1_Class_ut = TS1_Class[6560:8200]\n",
    "TS1_Class_dt = TS1_Class[8200:9840]\n",
    "TS1_Class_us = TS1_Class[9840:11480]\n",
    "TS1_Class_ds = TS1_Class[11480:13120]\n",
    "\n",
    "TS1_WE_Class_Normal = TS1_WE_Class[0:1640]\n",
    "TS1_WE_Class_Cyclic = TS1_WE_Class[1640:3280]\n",
    "TS1_WE_Class_Systematic = TS1_WE_Class[3280:4920]\n",
    "TS1_WE_Class_Stratified = TS1_WE_Class[4920:6560]\n",
    "TS1_WE_Class_ut = TS1_WE_Class[6560:8200]\n",
    "TS1_WE_Class_dt = TS1_WE_Class[8200:9840]\n",
    "TS1_WE_Class_us = TS1_WE_Class[9840:11480]\n",
    "TS1_WE_Class_ds = TS1_WE_Class[11480:13120]\n",
    "\n",
    "TS1_Nelson_Class_Normal = TS1_Nelson_Class[0:1640]\n",
    "TS1_Nelson_Class_Cyclic = TS1_Nelson_Class[1640:3280]\n",
    "TS1_Nelson_Class_Systematic = TS1_Nelson_Class[3280:4920]\n",
    "TS1_Nelson_Class_Stratified = TS1_Nelson_Class[4920:6560]\n",
    "TS1_Nelson_Class_ut = TS1_Nelson_Class[6560:8200]\n",
    "TS1_Nelson_Class_dt = TS1_Nelson_Class[8200:9840]\n",
    "TS1_Nelson_Class_us = TS1_Nelson_Class[9840:11480]\n",
    "TS1_Nelson_Class_ds = TS1_Nelson_Class[11480:13120]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_forest_Normal = predictions_forest[0:1640]\n",
    "predictions_forest_Cyclic = predictions_forest[1640:3280]\n",
    "predictions_forest_Systematic = predictions_forest[3280:4920]\n",
    "predictions_forest_Stratified = predictions_forest[4920:6560]\n",
    "predictions_forest_ut = predictions_forest[6560:8200]\n",
    "predictions_forest_dt = predictions_forest[8200:9840]\n",
    "predictions_forest_us = predictions_forest[9840:11480]\n",
    "predictions_forest_ds = predictions_forest[11480:13120]\n",
    "\n",
    "predictions_SVM_Normal = predictions_SVM[0:1640]\n",
    "predictions_SVM_Cyclic = predictions_SVM[1640:3280]\n",
    "predictions_SVM_Systematic = predictions_SVM[3280:4920]\n",
    "predictions_SVM_Stratified = predictions_SVM[4920:6560]\n",
    "predictions_SVM_ut = predictions_SVM[6560:8200]\n",
    "predictions_SVM_dt = predictions_SVM[8200:9840]\n",
    "predictions_SVM_us = predictions_SVM[9840:11480]\n",
    "predictions_SVM_ds = predictions_SVM[11480:13120]\n",
    "\n",
    "cm_perfect_normal = confusion_matrix(TS1_Class_Normal, TS1_Class_Normal)\n",
    "cm_perfect_Cyclic = confusion_matrix(TS1_Class_Cyclic, TS1_Class_Cyclic)\n",
    "cm_perfect_Systematic = confusion_matrix(TS1_Class_Systematic, TS1_Class_Systematic)\n",
    "cm_perfect_Stratified = confusion_matrix(TS1_Class_Stratified, TS1_Class_Stratified)\n",
    "cm_perfect_ut = confusion_matrix(TS1_Class_ut, TS1_Class_ut)\n",
    "cm_perfect_dt = confusion_matrix(TS1_Class_dt, TS1_Class_dt)\n",
    "cm_perfect_us = confusion_matrix(TS1_Class_us, TS1_Class_us)\n",
    "cm_perfect_ds = confusion_matrix(TS1_Class_ds, TS1_Class_ds)\n",
    "\n",
    "cm_WE_normal = confusion_matrix(TS1_Class_Normal, TS1_WE_Class_Normal)\n",
    "cm_WE_Cyclic = confusion_matrix(TS1_Class_Cyclic, TS1_WE_Class_Cyclic)\n",
    "cm_WE_Systematic = confusion_matrix(TS1_Class_Systematic, TS1_WE_Class_Systematic)\n",
    "cm_WE_Stratified = confusion_matrix(TS1_Class_Stratified, TS1_WE_Class_Stratified)\n",
    "cm_WE_ut = confusion_matrix(TS1_Class_ut, TS1_WE_Class_ut)\n",
    "cm_WE_dt = confusion_matrix(TS1_Class_dt, TS1_WE_Class_dt)\n",
    "cm_WE_us = confusion_matrix(TS1_Class_us, TS1_WE_Class_us)\n",
    "cm_WE_ds = confusion_matrix(TS1_Class_ds, TS1_WE_Class_ds)\n",
    "\n",
    "cm_Nelson_normal = confusion_matrix(TS1_Class_Normal, TS1_Nelson_Class_Normal)\n",
    "cm_Nelson_Cyclic = confusion_matrix(TS1_Class_Cyclic, TS1_Nelson_Class_Cyclic)\n",
    "cm_Nelson_Systematic = confusion_matrix(TS1_Class_Systematic, TS1_Nelson_Class_Systematic)\n",
    "cm_Nelson_Stratified = confusion_matrix(TS1_Class_Stratified, TS1_Nelson_Class_Stratified)\n",
    "cm_Nelson_ut = confusion_matrix(TS1_Class_ut, TS1_Nelson_Class_ut)\n",
    "cm_Nelson_dt = confusion_matrix(TS1_Class_dt, TS1_Nelson_Class_dt)\n",
    "cm_Nelson_us = confusion_matrix(TS1_Class_us, TS1_Nelson_Class_us)\n",
    "cm_Nelson_ds = confusion_matrix(TS1_Class_ds, TS1_Nelson_Class_ds)\n",
    "\n",
    "cm_forest_normal = confusion_matrix(TS1_Class_Normal, predictions_forest_Normal)\n",
    "cm_forest_Cyclic = confusion_matrix(TS1_Class_Cyclic, predictions_forest_Cyclic)\n",
    "cm_forest_Systematic = confusion_matrix(TS1_Class_Systematic, predictions_forest_Systematic)\n",
    "cm_forest_Stratified = confusion_matrix(TS1_Class_Stratified, predictions_forest_Stratified)\n",
    "cm_forest_ut = confusion_matrix(TS1_Class_ut, predictions_forest_ut)\n",
    "cm_forest_dt = confusion_matrix(TS1_Class_dt, predictions_forest_dt)\n",
    "cm_forest_us = confusion_matrix(TS1_Class_us, predictions_forest_us)\n",
    "cm_forest_ds = confusion_matrix(TS1_Class_ds, predictions_forest_ds)\n",
    "\n",
    "cm_SVM_normal = confusion_matrix(TS1_Class_Normal, predictions_SVM_Normal)\n",
    "cm_SVM_Cyclic = confusion_matrix(TS1_Class_Cyclic, predictions_SVM_Cyclic)\n",
    "cm_SVM_Systematic = confusion_matrix(TS1_Class_Systematic, predictions_SVM_Systematic)\n",
    "cm_SVM_Stratified = confusion_matrix(TS1_Class_Stratified, predictions_SVM_Stratified)\n",
    "cm_SVM_ut = confusion_matrix(TS1_Class_ut, predictions_SVM_ut)\n",
    "cm_SVM_dt = confusion_matrix(TS1_Class_dt, predictions_SVM_dt)\n",
    "cm_SVM_us = confusion_matrix(TS1_Class_us, predictions_SVM_us)\n",
    "cm_SVM_ds = confusion_matrix(TS1_Class_ds, predictions_SVM_ds)\n",
    "\n",
    "#Classification Report Global\n",
    "cf_WE = classification_report(TS1_Class, TS1_WE_Class)\n",
    "cf_Nelson = classification_report(TS1_Class, TS1_Nelson_Class)\n",
    "cf_forest = classification_report(TS1_Class, predictions_forest)\n",
    "cf_SVM = classification_report(TS1_Class, predictions_SVM)\n",
    "\n",
    "#Classification Report per Error\n",
    "cr_WE_normal = classification_report(TS1_Class_Normal, TS1_WE_Class_Normal)\n",
    "cr_WE_Cyclic = classification_report(TS1_Class_Cyclic, TS1_WE_Class_Cyclic)\n",
    "cr_WE_Systematic = classification_report(TS1_Class_Systematic, TS1_WE_Class_Systematic)\n",
    "cr_WE_Stratified = classification_report(TS1_Class_Stratified, TS1_WE_Class_Stratified)\n",
    "cr_WE_ut = classification_report(TS1_Class_ut, TS1_WE_Class_ut)\n",
    "cr_WE_dt = classification_report(TS1_Class_dt, TS1_WE_Class_dt)\n",
    "cr_WE_us = classification_report(TS1_Class_us, TS1_WE_Class_us)\n",
    "cr_WE_ds = classification_report(TS1_Class_ds, TS1_WE_Class_ds)\n",
    "\n",
    "cr_Nelson_normal = classification_report(TS1_Class_Normal, TS1_Nelson_Class_Normal)\n",
    "cr_Nelson_Cyclic = classification_report(TS1_Class_Cyclic, TS1_Nelson_Class_Cyclic)\n",
    "cr_Nelson_Systematic = classification_report(TS1_Class_Systematic, TS1_Nelson_Class_Systematic)\n",
    "cr_Nelson_Stratified = classification_report(TS1_Class_Stratified, TS1_Nelson_Class_Stratified)\n",
    "cr_Nelson_ut = classification_report(TS1_Class_ut, TS1_Nelson_Class_ut)\n",
    "cr_Nelson_dt = classification_report(TS1_Class_dt, TS1_Nelson_Class_dt)\n",
    "cr_Nelson_us = classification_report(TS1_Class_us, TS1_Nelson_Class_us)\n",
    "cr_Nelson_ds = classification_report(TS1_Class_ds, TS1_Nelson_Class_ds)\n",
    "\n",
    "cr_forest_normal = classification_report(TS1_Class_Normal, predictions_forest_Normal)\n",
    "cr_forest_Cyclic = classification_report(TS1_Class_Cyclic, predictions_forest_Cyclic)\n",
    "cr_forest_Systematic = classification_report(TS1_Class_Systematic, predictions_forest_Systematic)\n",
    "cr_forest_Stratified = classification_report(TS1_Class_Stratified, predictions_forest_Stratified)\n",
    "cr_forest_ut = classification_report(TS1_Class_ut, predictions_forest_ut)\n",
    "cr_forest_dt = classification_report(TS1_Class_dt, predictions_forest_dt)\n",
    "cr_forest_us = classification_report(TS1_Class_us, predictions_forest_us)\n",
    "cr_forest_ds = classification_report(TS1_Class_ds, predictions_forest_ds)\n",
    "\n",
    "cr_SVM_normal = classification_report(TS1_Class_Normal, predictions_SVM_Normal)\n",
    "cr_SVM_Cyclic = classification_report(TS1_Class_Cyclic, predictions_SVM_Cyclic)\n",
    "cr_SVM_Systematic = classification_report(TS1_Class_Systematic, predictions_SVM_Systematic)\n",
    "cr_SVM_Stratified = classification_report(TS1_Class_Stratified, predictions_SVM_Stratified)\n",
    "cr_SVM_ut = classification_report(TS1_Class_ut, predictions_SVM_ut)\n",
    "cr_SVM_dt = classification_report(TS1_Class_dt, predictions_SVM_dt)\n",
    "cr_SVM_us = classification_report(TS1_Class_us, predictions_SVM_us)\n",
    "cr_SVM_ds = classification_report(TS1_Class_ds, predictions_SVM_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_global = [cm_WE,cm_Nelson,cm_forest,cm_SVM]\n",
    "cm_normal=[cm_WE_normal,cm_Nelson_normal,cm_forest_normal,cm_SVM_normal]\n",
    "cm_Stratified=[cm_WE_Stratified,cm_Nelson_Stratified,cm_forest_Stratified,cm_SVM_Stratified]\n",
    "cm_Systematic=[cm_WE_Systematic,cm_Nelson_Systematic,cm_forest_Systematic,cm_SVM_Systematic]\n",
    "cm_Cyclic=[cm_WE_Cyclic,cm_Nelson_Cyclic,cm_forest_Cyclic,cm_SVM_Cyclic]\n",
    "cm_ut=[cm_WE_ut,cm_Nelson_ut,cm_forest_ut,cm_SVM_ut]\n",
    "cm_dt=[cm_WE_dt,cm_Nelson_dt,cm_forest_dt,cm_SVM_dt]\n",
    "cm_us=[cm_WE_us,cm_Nelson_us,cm_forest_us,cm_SVM_us]\n",
    "cm_ds=[cm_WE_ds,cm_Nelson_ds,cm_forest_ds,cm_SVM_ds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories=['FP','TP','FN','TN', 'FP']\n",
    "names=['WE', 'Nelson', 'iForest', 'SVM']\n",
    "colorsfill=['rgba(31, 119, 180,0.1)', 'rgba(255, 127, 14,0.1)',\n",
    "                       'rgba(44, 160, 44,0.1)', 'rgba(214, 39, 40,0.1)',\n",
    "                       'rgba(148, 103, 189,0.1)', 'rgba(140, 86, 75,0.1)',\n",
    "                       'rgba(227, 119, 194,0.1)', 'rgba(127, 127, 127,0.1)']\n",
    "colors=['rgba(31, 119, 180,1)', 'rgba(255, 127, 14,1)',\n",
    "                       'rgba(44, 160, 44,1)', 'rgba(214, 39, 40,1)',\n",
    "                       'rgba(148, 103, 189,1)', 'rgba(140, 86, 75,1)',\n",
    "                       'rgba(227, 119, 194,1)', 'rgba(127, 127, 127,1)']\n",
    "fig= make_subplots(rows=2, cols=4, specs=[[{'type': 'polar'}]*4]*2, subplot_titles=(\"Normal\", \"Stratified\",\n",
    " \"Systematic\", \"Cyclic\", \"Upward Trend\", \"Downward Trend\", \"Upward Shift\", \"Downward Shift\"))\n",
    "\n",
    "\n",
    "for i in range(len(cm_normal)):\n",
    "  fig.add_trace(go.Scatterpolar(\n",
    "      r=[cm_normal[i][0,1], cm_normal[i][1,1], cm_normal[i][1,0], cm_normal[i][0,0], cm_normal[i][0,1]],\n",
    "      theta=categories,\n",
    "      marker = dict(color=colors[i]),\n",
    "      fill='toself',\n",
    "      legendgroup=names[i],\n",
    "      subplot = \"polar1\",\n",
    "      name=names[i],\n",
    "      fillcolor=colorsfill[i]\n",
    "  ), 1, 1),\n",
    "  name=names[i],\n",
    "  fillcolor=colorsfill[i]\n",
    "  fig.add_trace(go.Scatterpolar(\n",
    "      r=[cm_Stratified[i][0,1], cm_Stratified[i][1,1], cm_Stratified[i][1,0], cm_Stratified[i][0,0], cm_Stratified[i][0,1]],\n",
    "      theta=categories,\n",
    "      marker = dict(color=colors[i]),\n",
    "      fill='toself',\n",
    "      legendgroup=names[i],\n",
    "      subplot = \"polar2\",\n",
    "      showlegend=False,\n",
    "      name=names[i],\n",
    "      fillcolor=colorsfill[i]\n",
    "  ), 1, 2)\n",
    "  fig.add_trace(go.Scatterpolar(\n",
    "      r=[cm_Systematic[i][0,1], cm_Systematic[i][1,1], cm_Systematic[i][1,0], cm_Systematic[i][0,0], cm_Systematic[i][0,1]],\n",
    "      theta=categories,\n",
    "      marker = dict(color=colors[i]),\n",
    "      fill='toself',\n",
    "      legendgroup=names[i],\n",
    "      subplot = \"polar3\",\n",
    "      showlegend=False,\n",
    "      name=names[i],\n",
    "      fillcolor=colorsfill[i]\n",
    "  ), 1, 3)\n",
    "  fig.add_trace(go.Scatterpolar(\n",
    "      r=[cm_Cyclic[i][0,1], cm_Cyclic[i][1,1], cm_Cyclic[i][1,0], cm_Cyclic[i][0,0], cm_Cyclic[i][0,1]],\n",
    "      theta=categories,\n",
    "      marker = dict(color=colors[i]),\n",
    "      fill='toself',\n",
    "      legendgroup=names[i],\n",
    "      subplot = \"polar4\",\n",
    "      showlegend=False,\n",
    "      name=names[i],\n",
    "      fillcolor=colorsfill[i]\n",
    "  ), 1, 4)\n",
    "  fig.add_trace(go.Scatterpolar(\n",
    "      r=[cm_ut[i][0,1], cm_ut[i][1,1], cm_ut[i][1,0], cm_ut[i][0,0], cm_ut[i][0,1]],\n",
    "      theta=categories,\n",
    "      marker = dict(color=colors[i]),\n",
    "      fill='toself',\n",
    "      legendgroup=names[i],\n",
    "      subplot = \"polar4\",\n",
    "      showlegend=False,\n",
    "      name=names[i],\n",
    "      fillcolor=colorsfill[i]\n",
    "  ), 2, 1)\n",
    "  fig.add_trace(go.Scatterpolar(\n",
    "      r=[cm_dt[i][0,1], cm_dt[i][1,1], cm_dt[i][1,0], cm_dt[i][0,0], cm_dt[i][0,1]],\n",
    "      theta=categories,\n",
    "      marker = dict(color=colors[i]),\n",
    "      fill='toself',\n",
    "      legendgroup=names[i],\n",
    "      subplot = \"polar4\",\n",
    "      showlegend=False,\n",
    "      name=names[i],\n",
    "      fillcolor=colorsfill[i]\n",
    "  ), 2, 2)\n",
    "  fig.add_trace(go.Scatterpolar(\n",
    "      r=[cm_us[i][0,1], cm_us[i][1,1], cm_us[i][1,0], cm_us[i][0,0], cm_us[i][0,1]],\n",
    "      theta=categories,\n",
    "      marker = dict(color=colors[i]),\n",
    "      fill='toself',\n",
    "      legendgroup=names[i],\n",
    "      subplot = \"polar4\",\n",
    "      showlegend=False,\n",
    "      name=names[i],\n",
    "      fillcolor=colorsfill[i]\n",
    "  ), 2, 3)\n",
    "  fig.add_trace(go.Scatterpolar(\n",
    "      r=[cm_ds[i][0,1], cm_ds[i][1,1], cm_ds[i][1,0], cm_ds[i][0,0], cm_ds[i][0,1]],\n",
    "      theta=categories,\n",
    "      marker = dict(color=colors[i]),\n",
    "      fill='toself',\n",
    "      legendgroup=names[i],\n",
    "      subplot = \"polar4\",\n",
    "      showlegend=False,\n",
    "      name=names[i],\n",
    "      fillcolor=colorsfill[i]\n",
    "  ), 2, 4)\n",
    "\n",
    "fig.update_layout(\n",
    "    polar1=dict(\n",
    "    radialaxis=dict(\n",
    "    visible=True,\n",
    "    range=[0, 1900]),\n",
    "    angularaxis=dict(\n",
    "    rotation= 45,\n",
    "    direction='clockwise')\n",
    "    ),\n",
    "    polar2=dict(\n",
    "    radialaxis=dict(\n",
    "    visible=True,\n",
    "    range=[0, 900]),\n",
    "    angularaxis=dict(\n",
    "    rotation= 45,\n",
    "    direction='clockwise')\n",
    "    ),\n",
    "    polar3=dict(\n",
    "    radialaxis=dict(\n",
    "    visible=True,\n",
    "    range=[0, 900]),\n",
    "    angularaxis=dict(\n",
    "    rotation= 45,\n",
    "    direction='clockwise')\n",
    "    ),\n",
    "    polar4=dict(\n",
    "    radialaxis=dict(\n",
    "    visible=True,\n",
    "    range=[0, 900]),\n",
    "    angularaxis=dict(\n",
    "    rotation= 45,\n",
    "    direction='clockwise')\n",
    "    ),\n",
    "    polar5=dict(\n",
    "    radialaxis=dict(\n",
    "    visible=True,\n",
    "    range=[0, 900]),\n",
    "    angularaxis=dict(\n",
    "    rotation= 45,\n",
    "    direction='clockwise')\n",
    "    ),\n",
    "    polar6=dict(\n",
    "    radialaxis=dict(\n",
    "    visible=True,\n",
    "    range=[0, 900]),\n",
    "    angularaxis=dict(\n",
    "    rotation= 45,\n",
    "    direction='clockwise')\n",
    "    ),\n",
    "    polar7=dict(\n",
    "    radialaxis=dict(\n",
    "    visible=True,\n",
    "    range=[0, 900]),\n",
    "    angularaxis=dict(\n",
    "    rotation= 45,\n",
    "    direction='clockwise')\n",
    "    ),\n",
    "    polar8=dict(\n",
    "    radialaxis=dict(\n",
    "    visible=True,\n",
    "    range=[0, 900]),\n",
    "    angularaxis=dict(\n",
    "    rotation= 45,\n",
    "    direction='clockwise')\n",
    "    ),\n",
    "    height=700,\n",
    "    width=1250,\n",
    "    title = 'Classification Matrix per Error Type'\n",
    "  )\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=go.Figure()\n",
    "for i in range(len(cm_global)):\n",
    "    fig.add_trace(go.Scatterpolar(\n",
    "        r=[cm_global[i][0,1], cm_global[i][1,1], cm_global[i][1,0], cm_global[i][0,0], cm_global[i][0,1]],\n",
    "        theta=categories,\n",
    "        marker = dict(color=colors[i]),\n",
    "        fill='toself',\n",
    "        legendgroup=names[i],\n",
    "        subplot = \"polar1\",\n",
    "        name=names[i],\n",
    "        fillcolor=colorsfill[i])\n",
    "    )\n",
    "fig.update_layout(height=500, width=500, title='Global Classification Matrix',\n",
    "polar=dict(\n",
    "    radialaxis=dict(\n",
    "    visible=True,\n",
    "    range=[0, 7300]),\n",
    "    angularaxis=dict(\n",
    "    rotation= 45,\n",
    "    direction='clockwise')\n",
    "    ))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_tuning = joblib.load('ML_Models/ML_SVM_tuning.pkl')\n",
    "iforest_tuning = joblib.load('ML_Models/ML_iforest_tuning.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Bar(x=np.arange(1,11), y=iforest_tuning.cv_results_['mean_test_F1'], text=np.round(iforest_tuning.cv_results_['mean_test_F1'],3)))\n",
    "fig.update_layout(title='Mean F1-Score of the Different Cross-validation Tests for Each Combination of Hyperparameters',\n",
    "                   yaxis_title='F1-Score',\n",
    "                   xaxis=dict(\n",
    "                    title='Combination Number',\n",
    "                    tickmode='linear'))\n",
    "fig.update_yaxes(range=[0.6, 0.99])\n",
    "\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Bar(x=np.arange(1,11), y=iforest_tuning.cv_results_['std_test_F1'], text=np.round(iforest_tuning.cv_results_['std_test_F1'],3)))\n",
    "fig.update_layout(title='Standard Deviation of the F1-Score of the Different Cross-validation Tests<br>for Each Combination of Hyperparameters',\n",
    "                   yaxis_title='Standard Deviation',\n",
    "                   xaxis=dict(\n",
    "                    title='Combination Number',\n",
    "                    tickmode='linear'))\n",
    "fig.update_yaxes(range=[0, 0.006])\n",
    "\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Bar(x=np.arange(1,11), y=iforest_tuning.cv_results_['mean_test_F1'], text=np.round(iforest_tuning.cv_results_['mean_test_F1'],3)))\n",
    "fig.update_layout(title='Mean F1-Score of the Different Cross-validation Tests for Each Combination of Hyperparameters',\n",
    "                   yaxis_title='F1-Score',\n",
    "                   xaxis=dict(\n",
    "                    title='Combination Number',\n",
    "                    tickmode='linear'))\n",
    "fig.update_yaxes(range=[0.6, 0.99])\n",
    "\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Bar(x=np.arange(1,43), y=SVM_tuning.cv_results_['mean_test_score'][0:42], text=np.round(SVM_tuning.cv_results_['mean_test_score'][0:42],3),\n",
    "marker_color= 'blue'))\n",
    "fig.update_layout(title='Mean F1-Score of the Different Cross-validation Tests for Each Combination of Hyperparameters<br>Iternation 1',\n",
    "                   yaxis_title='F1-Score',\n",
    "                   xaxis=dict(\n",
    "                    title='Combination Number',\n",
    "                    tickmode='linear'))\n",
    "fig.update_yaxes(range=[0, 0.99])\n",
    "\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Bar(x=['11','40','33','39','15','36','18','31','26','32','38','25','22','29'], y=SVM_tuning.cv_results_['mean_test_score'][42:56], text=np.round(SVM_tuning.cv_results_['mean_test_score'][42:56],3),\n",
    "marker_color='red'))\n",
    "fig.update_layout(title='Mean F1-Score of the Different Cross-validation Tests for Each Combination of Hyperparameters<br>Iternation 2',\n",
    "                   yaxis_title='F1-Score',\n",
    "                   xaxis=dict(\n",
    "                    title='Combination Number',\n",
    "                    tickmode='linear'))\n",
    "fig.update_yaxes(range=[0, 0.99])\n",
    "\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Bar(x=['22','25','38','32','29'], y=SVM_tuning.cv_results_['mean_test_score'][56:61], text=np.round(SVM_tuning.cv_results_['mean_test_score'][56:61],3),\n",
    "marker_color='yellow'))\n",
    "fig.update_layout(title='Mean F1-Score of the Different Cross-validation Tests for Each Combination of Hyperparameters<br>Iternation 3',\n",
    "                   yaxis_title='F1-Score',\n",
    "                   xaxis=dict(\n",
    "                    title='Combination Number',\n",
    "                    tickmode='linear'))\n",
    "fig.update_yaxes(range=[0, 0.99])\n",
    "\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Bar(x=['29','32'], y=SVM_tuning.cv_results_['mean_test_score'][61:63], text=np.round(SVM_tuning.cv_results_['mean_test_score'][61:63],3),\n",
    "marker_color='green'))\n",
    "fig.update_layout(title='Mean F1-Score of the Different Cross-validation Tests for Each Combination of Hyperparameters<br>Iternation 4',\n",
    "                   yaxis_title='F1-Score',\n",
    "                   xaxis=dict(\n",
    "                    title='Combination Number',\n",
    "                    tickmode='linear'))\n",
    "fig.update_yaxes(range=[0, 0.99])\n",
    "\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cf_WE, cf_Nelson, cf_forest, cf_SVM)\n",
    "print(precision_score(TS1_Class, TS1_WE_Class), precision_score(TS1_Class, TS1_Nelson_Class),\n",
    "precision_score(TS1_Class, predictions_forest), precision_score(TS1_Class, predictions_SVM))\n",
    "print(recall_score(TS1_Class, TS1_WE_Class), recall_score(TS1_Class, TS1_Nelson_Class),\n",
    "recall_score(TS1_Class, predictions_forest), recall_score(TS1_Class, predictions_SVM))\n",
    "print(f1_score(TS1_Class, TS1_WE_Class), f1_score(TS1_Class, TS1_Nelson_Class),\n",
    "f1_score(TS1_Class, predictions_forest), f1_score(TS1_Class, predictions_SVM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TS1_clas_testing_ = pd.read_csv(\"Data/TimeSeries1_Classification.csv\", index_col = 0)\n",
    "TS1_clas_testing_ = TS1_clas_testing_.iloc[1280:1600, :]\n",
    "def sw(X, time_steps):\n",
    "    vect =[]\n",
    "    for l in range (X.shape[0]):\n",
    "\n",
    "        for i in range(X.shape[1] - time_steps+1):\n",
    "            \n",
    "            v = X[l, i:(i + time_steps)]\n",
    "            vect.append(v)\n",
    "\n",
    "    return np.array(vect)\n",
    "\n",
    "df= sw(np.array(TS1_clas_testing_), 20)\n",
    "summ=np.sum(df, axis=1)\n",
    "\n",
    "\n",
    "df=pd.DataFrame(np.transpose([summ, np.array(predictions_forest).astype(str)]), columns=['Anomalies in Window','Classification'])\n",
    "df2 = df.groupby(['Anomalies in Window','Classification']).size().reset_index(name='Count')\n",
    "df2['Anomalies in Window']=df2['Anomalies in Window'].astype(int)\n",
    "df2.sort_values(['Anomalies in Window'])\n",
    "df3 = df.groupby('Anomalies in Window').count()\n",
    "total= np.array(df3)\n",
    "total= np.repeat(total, 2)\n",
    "percentage=np.divide(np.array(df2.iloc[:,2]),total)\n",
    "\n",
    "df2.insert(3, 'percentage', percentage)\n",
    "df0=df2[df2['Classification']=='0']\n",
    "df1=df2[df2['Classification']=='1']\n",
    "\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Bar(x=df0['Anomalies in Window'], y=df0['percentage'],name='0'))\n",
    "fig.add_trace(go.Bar(x=df1['Anomalies in Window'], y=df1['percentage'],name='1'))\n",
    "fig.update_layout(barmode='stack')\n",
    "fig.update_layout(title='Classification performance based on the Anomalies per Window for Isolation Forest',\n",
    "                   yaxis_title='Percent of Total Windows',\n",
    "                   xaxis=dict(\n",
    "                    title='Anomalies per Window',\n",
    "                    tickmode='linear'))\n",
    "\n",
    "\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TS1_clas_testing_ = pd.read_csv(\"Data/TimeSeries1_Classification.csv\", index_col = 0)\n",
    "TS1_clas_testing_ = TS1_clas_testing_.iloc[1280:1600, :]\n",
    "def sw(X, time_steps):\n",
    "    vect =[]\n",
    "    for l in range (X.shape[0]):\n",
    "\n",
    "        for i in range(X.shape[1] - time_steps+1):\n",
    "            \n",
    "            v = X[l, i:(i + time_steps)]\n",
    "            vect.append(v)\n",
    "\n",
    "    return np.array(vect)\n",
    "\n",
    "df= sw(np.array(TS1_clas_testing_), 20)\n",
    "summ=np.sum(df, axis=1)\n",
    "\n",
    "\n",
    "df=pd.DataFrame(np.transpose([summ, np.array(predictions_SVM).astype(str)]), columns=['Anomalies in Window','Classification'])\n",
    "df2 = df.groupby(['Anomalies in Window','Classification']).size().reset_index(name='Count')\n",
    "df2['Anomalies in Window']=df2['Anomalies in Window'].astype(int)\n",
    "df2.sort_values(['Anomalies in Window'])\n",
    "df3 = df.groupby('Anomalies in Window').count()\n",
    "total= np.array(df3)\n",
    "total= np.repeat(total, 2)\n",
    "percentage=np.divide(np.array(df2.iloc[:,2]),total)\n",
    "\n",
    "df2.insert(3, 'percentage', percentage)\n",
    "df0=df2[df2['Classification']=='0']\n",
    "df1=df2[df2['Classification']=='1']\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Bar(x=df0['Anomalies in Window'], y=df0['percentage'],name='0'))\n",
    "fig.add_trace(go.Bar(x=df1['Anomalies in Window'], y=df1['percentage'],name='1'))\n",
    "fig.update_layout(barmode='stack')\n",
    "fig.update_layout(title='Classification performance based on the Anomalies per Window for Isolation Forest',\n",
    "                   yaxis_title='Percent of Total Windows',\n",
    "                   xaxis=dict(\n",
    "                    title='Anomalies per Window',\n",
    "                    tickmode='linear'))\n",
    "\n",
    "\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TS1_clas_testing_ = pd.read_csv(\"Data/TimeSeries1_Classification.csv\", index_col = 0)\n",
    "TS1_clas_testing_ = TS1_clas_testing_.iloc[1280:1600, :]\n",
    "def sw(X, time_steps):\n",
    "    vect =[]\n",
    "    for l in range (X.shape[0]):\n",
    "\n",
    "        for i in range(X.shape[1] - time_steps+1):\n",
    "            \n",
    "            v = X[l, i:(i + time_steps)]\n",
    "            vect.append(v)\n",
    "\n",
    "    return np.array(vect)\n",
    "\n",
    "df= sw(np.array(TS1_clas_testing_), 20)\n",
    "summ=np.sum(df, axis=1)\n",
    "\n",
    "\n",
    "df=pd.DataFrame(np.transpose([summ, np.array(TS1_WE_Class).astype(str)]), columns=['Anomalies in Window','Classification'])\n",
    "df2 = df.groupby(['Anomalies in Window','Classification']).size().reset_index(name='Count')\n",
    "df2['Anomalies in Window']=df2['Anomalies in Window'].astype(int)\n",
    "df2.sort_values(['Anomalies in Window'])\n",
    "df3 = df.groupby('Anomalies in Window').count()\n",
    "total= np.array(df3)\n",
    "total= np.repeat(total, 2)\n",
    "percentage=np.divide(np.array(df2.iloc[:,2]),total)\n",
    "\n",
    "df2.insert(3, 'percentage', percentage)\n",
    "df0=df2[df2['Classification']=='0']\n",
    "df1=df2[df2['Classification']=='1']\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Bar(x=df0['Anomalies in Window'], y=df0['percentage'],name='0'))\n",
    "fig.add_trace(go.Bar(x=df1['Anomalies in Window'], y=df1['percentage'],name='1'))\n",
    "fig.update_layout(barmode='stack')\n",
    "fig.update_layout(title='Classification performance based on the Anomalies per Window for Isolation Forest',\n",
    "                   yaxis_title='Percent of Total Windows',\n",
    "                   xaxis=dict(\n",
    "                    title='Anomalies per Window',\n",
    "                    tickmode='linear'))\n",
    "\n",
    "\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def heatmap(x, y, title, **kwargs):\n",
    "    if 'color' in kwargs:\n",
    "        color = kwargs['color']\n",
    "    else:\n",
    "        color = [1]*len(x)\n",
    "\n",
    "    if 'palette' in kwargs:\n",
    "        palette = kwargs['palette']\n",
    "        n_colors = len(palette)\n",
    "    else:\n",
    "        n_colors = 256 # Use 256 colors for the diverging color palette\n",
    "        palette = sns.diverging_palette(20, 145, n=n_colors) \n",
    "\n",
    "    if 'color_range' in kwargs:\n",
    "        color_min, color_max = kwargs['color_range']\n",
    "    else:\n",
    "        color_min, color_max = min(color), max(color) # Range of values that will be mapped to the palette, i.e. min and max possible correlation\n",
    "\n",
    "    def value_to_color(val):\n",
    "        if color_min == color_max:\n",
    "            return palette[-1]\n",
    "        else:\n",
    "            val_position = float((val - color_min)) / (color_max - color_min) # position of value in the input range, relative to the length of the input range\n",
    "            val_position = min(max(val_position, 0), 1) # bound the position betwen 0 and 1\n",
    "            ind = int(val_position * (n_colors - 1)) # target index in the color palette\n",
    "            return palette[ind]\n",
    "\n",
    "    if 'size' in kwargs:\n",
    "        size = kwargs['size']\n",
    "    else:\n",
    "        size = [1]*len(x)\n",
    "\n",
    "    if 'size_range' in kwargs:\n",
    "        size_min, size_max = kwargs['size_range'][0], kwargs['size_range'][1]\n",
    "    else:\n",
    "        size_min, size_max = min(size), max(size)\n",
    "\n",
    "    size_scale = kwargs.get('size_scale', 500)\n",
    "\n",
    "    def value_to_size(val):\n",
    "        if size_min == size_max:\n",
    "            return 1 * size_scale\n",
    "        else:\n",
    "            val_position = (val - size_min) * 0.99 / (size_max - size_min) + 0.01 # position of value in the input range, relative to the length of the input range\n",
    "            val_position = min(max(val_position, 0), 1) # bound the position betwen 0 and 1\n",
    "            return val_position * size_scale\n",
    "    if 'x_order' in kwargs: \n",
    "        x_names = [t for t in kwargs['x_order']]\n",
    "    else:\n",
    "        x_names = [t for t in sorted(set([v for v in x]))]\n",
    "    x_to_num = {p[1]:p[0] for p in enumerate(x_names)}\n",
    "\n",
    "    if 'y_order' in kwargs: \n",
    "        y_names = [t for t in kwargs['y_order']]\n",
    "    else:\n",
    "        y_names = [t for t in sorted(set([v for v in y]))]\n",
    "    y_to_num = {p[1]:p[0] for p in enumerate(y_names)}\n",
    "\n",
    "    \n",
    "    plot_grid = plt.GridSpec(1, 15, hspace=0.2, wspace=0.1) # Setup a 1x15 grid\n",
    "    ax = plt.subplot(plot_grid[:,:-1]) # Use the left 14/15ths of the grid for the main plot\n",
    "\n",
    "    plt.title(title)\n",
    "\n",
    "    marker = kwargs.get('marker', 'o')\n",
    "\n",
    "    kwargs_pass_on = {k:v for k,v in kwargs.items() if k not in [\n",
    "         'color', 'palette', 'color_range', 'size', 'size_range', 'size_scale', 'marker', 'x_order', 'y_order'\n",
    "    ]}\n",
    "\n",
    "    ax.scatter(\n",
    "        x=[x_to_num[v] for v in x],\n",
    "        y=[y_to_num[v] for v in y],\n",
    "        marker=marker,\n",
    "        alpha = 0.7,\n",
    "        s=[value_to_size(v) for v in size], \n",
    "        c=['green','green','red','red'],\n",
    "        **kwargs_pass_on\n",
    "    )\n",
    "\n",
    "    ax.set_xticks([v for k,v in x_to_num.items()])\n",
    "    ax.set_xticklabels([k for k in x_to_num], horizontalalignment='right')\n",
    "    ax.set_yticks([v for k,v in y_to_num.items()])\n",
    "    ax.set_yticklabels([k for k in y_to_num])\n",
    "\n",
    "    ax.grid(False, 'major')\n",
    "    ax.grid(True, 'minor')\n",
    "    ax.set_xticks([t + 0.5 for t in ax.get_xticks()], minor=True)\n",
    "    ax.set_yticks([t + 0.5 for t in ax.get_yticks()], minor=True)\n",
    "    ax.xaxis.tick_top()\n",
    "    ax.xaxis.set_label_position('top') \n",
    "\n",
    "    ax.set_xlim([-0.5, max([v for v in x_to_num.values()]) + 0.5])\n",
    "    ax.set_ylim([-0.5, max([v for v in y_to_num.values()]) + 0.5])\n",
    "    ax.set_facecolor('white')\n",
    "\n",
    "    secax = ax.secondary_xaxis('bottom')\n",
    "    secax.set_xticks([])\n",
    "    secax.set_xlabel('Predicted')\n",
    "\n",
    "    secax = ax.secondary_yaxis('right')\n",
    "    secax.set_yticks([])\n",
    "    secax.set_ylabel('Actual', rotation='vertical')\n",
    "\n",
    "        \n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "heatmap(\n",
    "        x=['I C','OOC', 'I C','OOC'], # Column to use as horizontal dimension \n",
    "        y=['I C','OOC','OOC','I C'], # Column to use as vertical dimension\n",
    "        x_order=['I C', 'OOC'], # Sort order for x labels\n",
    "        y_order=['OOC', 'I C'], # Sort order for y labels \n",
    "        size_scale=11000, # Change this to see how it affects the plot\n",
    "\n",
    "        size=[cm_ds[0][0,0],cm_ds[0][1,1], cm_ds[0][1,0],cm_ds[0][0,1]], # Values to map to size, here we use number of items in each bucket\n",
    "        title='WE'\n",
    "        # size=[cm_ds[1][0,0],cm_ds[1][1,1], cm_ds[1][1,0],cm_ds[1][0,1]], # Values to map to size, here we use number of items in each bucket\n",
    "        # title='Nelson'\n",
    "        # size=[cm_ds[2][0,0],cm_ds[2][1,1], cm_ds[2][1,0],cm_ds[2][0,1]], # Values to map to size, here we use number of items in each bucket\n",
    "        # title='Isolation Forest'\n",
    "        # size=[cm_ds[3][0,0],cm_ds[3][1,1], cm_ds[3][1,0],cm_ds[3][0,1]], # Values to map to size, here we use number of items in each bucket\n",
    "        # title='SVM'\n",
    "    )\n",
    "\n",
    "plt.figure(dpi=4000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heatmap(x, y, title, alf, **kwargs):\n",
    "    if 'color' in kwargs:\n",
    "        color = kwargs['color']\n",
    "    else:\n",
    "        color = [1]*len(x)\n",
    "\n",
    "    if 'palette' in kwargs:\n",
    "        palette = kwargs['palette']\n",
    "        n_colors = len(palette)\n",
    "    else:\n",
    "        n_colors = 256 # Use 256 colors for the diverging color palette\n",
    "        palette = sns.diverging_palette(20, 145, n=n_colors) \n",
    "\n",
    "    if 'color_range' in kwargs:\n",
    "        color_min, color_max = kwargs['color_range']\n",
    "    else:\n",
    "        color_min, color_max = min(color), max(color) # Range of values that will be mapped to the palette, i.e. min and max possible correlation\n",
    "\n",
    "    def value_to_color(val):\n",
    "        if color_min == color_max:\n",
    "            return palette[-1]\n",
    "        else:\n",
    "            val_position = float((val - color_min)) / (color_max - color_min) # position of value in the input range, relative to the length of the input range\n",
    "            val_position = min(max(val_position, 0), 1) # bound the position betwen 0 and 1\n",
    "            ind = int(val_position * (n_colors - 1)) # target index in the color palette\n",
    "            return palette[ind]\n",
    "\n",
    "    if 'size' in kwargs:\n",
    "        size = kwargs['size']\n",
    "    else:\n",
    "        size = [1]*len(x)\n",
    "\n",
    "    if 'size_range' in kwargs:\n",
    "        size_min, size_max = kwargs['size_range'][0], kwargs['size_range'][1]\n",
    "    else:\n",
    "        size_min, size_max = min(size), max(size)\n",
    "\n",
    "    size_scale = kwargs.get('size_scale', 500)\n",
    "\n",
    "    def value_to_size(val):\n",
    "        if size_min == size_max:\n",
    "            return 1 * size_scale\n",
    "        else:\n",
    "            val_position = (val - size_min) * 0.99 / (size_max - size_min) + 0.01 # position of value in the input range, relative to the length of the input range\n",
    "            val_position = min(max(val_position, 0), 1) # bound the position betwen 0 and 1\n",
    "            return val_position * size_scale\n",
    "    if 'x_order' in kwargs: \n",
    "        x_names = [t for t in kwargs['x_order']]\n",
    "    else:\n",
    "        x_names = [t for t in sorted(set([v for v in x]))]\n",
    "    x_to_num = {p[1]:p[0] for p in enumerate(x_names)}\n",
    "\n",
    "    if 'y_order' in kwargs: \n",
    "        y_names = [t for t in kwargs['y_order']]\n",
    "    else:\n",
    "        y_names = [t for t in sorted(set([v for v in y]))]\n",
    "    y_to_num = {p[1]:p[0] for p in enumerate(y_names)}\n",
    "\n",
    "    \n",
    "    plot_grid = plt.GridSpec(1, 15, hspace=0.2, wspace=0.1) # Setup a 1x15 grid\n",
    "    ax = plt.subplot(plot_grid[:,:-1]) # Use the left 14/15ths of the grid for the main plot\n",
    "\n",
    "    plt.title(title)\n",
    "\n",
    "    marker = kwargs.get('marker', 'o')\n",
    "\n",
    "    kwargs_pass_on = {k:v for k,v in kwargs.items() if k not in [\n",
    "         'color', 'palette', 'color_range', 'size', 'size_range', 'size_scale', 'marker', 'x_order', 'y_order'\n",
    "    ]}\n",
    "\n",
    "    ax.scatter(\n",
    "        x=[x_to_num[v] for v in x],\n",
    "        y=[y_to_num[v] for v in y],\n",
    "        marker=marker,\n",
    "        alpha = alf,\n",
    "        s=[value_to_size(v) for v in size], \n",
    "        c=['green','green','red','red',\n",
    "        'green','green','red','red',\n",
    "        'green','green','red','red',\n",
    "        'green','green','red','red'],\n",
    "        **kwargs_pass_on\n",
    "    )\n",
    "\n",
    "    ax.set_xticks([v for k,v in x_to_num.items()])\n",
    "    ax.set_xticklabels([k for k in x_to_num], horizontalalignment='right')\n",
    "    ax.set_yticks([v for k,v in y_to_num.items()])\n",
    "    ax.set_yticklabels([k for k in y_to_num])\n",
    "\n",
    "    ax.grid(False, 'major')\n",
    "    ax.grid(True, 'minor')\n",
    "    ax.set_xticks([t + 0.5 for t in ax.get_xticks()], minor=True)\n",
    "    ax.set_yticks([t + 0.5 for t in ax.get_yticks()], minor=True)\n",
    "    ax.xaxis.tick_top()\n",
    "    ax.xaxis.set_label_position('top') \n",
    "\n",
    "    ax.set_xlim([-0.5, max([v for v in x_to_num.values()]) + 0.5])\n",
    "    ax.set_ylim([-0.5, max([v for v in y_to_num.values()]) + 0.5])\n",
    "    ax.set_facecolor('white')\n",
    "\n",
    "    secax = ax.secondary_xaxis('bottom')\n",
    "    secax.set_xticks([])\n",
    "    secax.set_xlabel('Predicted')\n",
    "\n",
    "    secax = ax.secondary_yaxis('right')\n",
    "    secax.set_yticks([])\n",
    "    secax.set_ylabel('Actual', rotation='vertical')\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "heatmap(\n",
    "        x=['I C','OOC', 'I C','OOC',\n",
    "        'I C','OOC', 'I C','OOC',\n",
    "        'I C','OOC', 'I C','OOC',\n",
    "        'I C','OOC', 'I C','OOC'], # Column to use as horizontal dimension \n",
    "        y=['I C','OOC','OOC','I C',\n",
    "        'I C','OOC','OOC','I C',\n",
    "        'I C','OOC','OOC','I C',\n",
    "        'I C','OOC','OOC','I C'], # Column to use as vertical dimension\n",
    "        x_order=['I C', 'OOC'], # Sort order for x labels\n",
    "        y_order=['OOC', 'I C'], # Sort order for y labels \n",
    "        size_scale=11000, # Change this to see how it affects the plot\n",
    "\n",
    "        size=[cm_normal[0][0,0],cm_normal[0][1,1], cm_normal[0][1,0],cm_normal[0][0,1],\n",
    "        cm_normal[1][0,0],cm_normal[1][1,1], cm_normal[1][1,0],cm_normal[1][0,1],\n",
    "        cm_normal[2][0,0],cm_normal[2][1,1], cm_normal[2][1,0],cm_normal[2][0,1],\n",
    "        cm_normal[3][0,0],cm_normal[3][1,1], cm_normal[3][1,0],cm_normal[3][0,1]],\n",
    "        alf=[\n",
    "        0.7,0.7,0.7,0.7,\n",
    "        0,0,0,0,\n",
    "        0,0,0,0,\n",
    "        0,0,0,0\n",
    "        ],\n",
    "        title='WE'\n",
    "    )\n",
    "\n",
    "plt.figure(dpi=4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cr_SVM_Stratified, cr_SVM_Systematic, cr_SVM_Cyclic,cr_SVM_ut,cr_SVM_dt,cr_SVM_us,cr_SVM_ds)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "155419e57043e3c6c91350c5428c6cc33fefa50a0d623da8550d7adba7f4f47b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
