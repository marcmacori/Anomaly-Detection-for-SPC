{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.model_selection import RandomizedSearchCV, KFold, cross_validate\n",
    "from sklearn.metrics import f1_score, make_scorer, precision_score, recall_score, average_precision_score, roc_auc_score\n",
    "import joblib\n",
    "import os\n",
    "os.chdir(r'C:/Users/Marc/Desktop/TFG/R Files/Anomaly Detection for SPC')\n",
    "from Src.FeatureExt.ML_AD_Preprocessing import *\n",
    "\n",
    "#Pre-processing\n",
    "#Import data\n",
    "TS1 = pd.read_csv(\"Data\\TimeSeries1.csv\", index_col = 0)\n",
    "\n",
    "#Standardize data based on first 20 points of chart, which is supposed in control       \n",
    "X_train = stdvector(TS1)\n",
    "\n",
    "X_train = sw_dataset_3(X_train, 20)\n",
    "X_train = np.transpose(X_train)\n",
    "X_train = pd.DataFrame(X_train,\\\n",
    "     columns = [\"last_value\", \"mean20\", \"sigma20\",\"mean5\", \"sigma5\", \"find_if\", \"kurtosis\",\"dir_change\", 'wavg', 'slope', 'meancross', 'rdist', 'brange'])\n",
    "\n",
    "#Split dataset for training\n",
    "split= int(4/5 * X_train.shape[0])\n",
    "\n",
    "X_train = X_train.iloc[0:split, :]\n",
    "\n",
    "#Structuring labels for hyperparameter tuning\n",
    "TS1_Class = pd.read_csv(\"Data\\TimeSeries1_Classification.csv\", index_col = 0)\n",
    "TS1_Class = TS1_Class.iloc[0:1280, 19:60]\n",
    "X_labels = np.array(TS1_Class).reshape(TS1_Class.size)\n",
    "X_labels[X_labels == 1] = -1\n",
    "X_labels[X_labels == 0] = 1\n",
    "\n",
    "\n",
    "#Define Model\n",
    "random_state = np.random.RandomState(42)\n",
    "iforest = IsolationForest()\n",
    "\n",
    "#Cross Validation\n",
    "cv = KFold(n_splits = 5, shuffle=True,  random_state = 123)\n",
    "sc = make_scorer(f1_score)\n",
    "\n",
    "iforestcv=cross_validate(iforest, X_train, X_labels, cv = cv, scoring=sc)\n",
    "print(iforestcv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(iforestcv['test_score']),\n",
    "np.std(iforestcv['test_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5666211429141634 0.0034163356308370614\n",
      "0.7931958927887024 0.0038542172289611136\n"
     ]
    }
   ],
   "source": [
    "#Libraries\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from sklearnex import patch_sklearn \n",
    "patch_sklearn()\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import svm\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingGridSearchCV, KFold \n",
    "from sklearn.metrics import f1_score, make_scorer, accuracy_score, precision_score, recall_score, average_precision_score\n",
    "import joblib\n",
    "os.chdir(r'C:/Users/Marc/Desktop/TFG/R Files/Anomaly Detection for SPC')\n",
    "from Src.FeatureExt.ML_AD_Preprocessing import *\n",
    "\n",
    "#Pre-processing\n",
    "#Import data\n",
    "TS1 = pd.read_csv(\"Data\\TimeSeries1.csv\", index_col = 0)\n",
    "\n",
    "#Standardize data based on first 20 points of chart, which is supposed in control       \n",
    "X_train = stdvector(TS1)  \n",
    "\n",
    "#Creating sliding windows for each TS and get features\n",
    "X_train = sw_dataset_3(X_train, 20)\n",
    "X_train = np.transpose(X_train)\n",
    "scaler = StandardScaler()\n",
    "scaler = scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_train = pd.DataFrame(X_train,\\\n",
    "     columns = [\"last_value\", \"mean20\", \"sigma20\",\"mean5\", \"sigma5\", \"find_if\", \"kurtosis\",\"dir_change\", 'wavg', 'slope', 'meancross', 'rdist', 'brange'])\n",
    "\n",
    "#Split dataset for training\n",
    "split= int(4/5 * X_train.shape[0])\n",
    "\n",
    "X_train = X_train.iloc[0:split, :]\n",
    "\n",
    "#Training supervised SVM\n",
    "#Structuring labels\n",
    "TS1_Class = pd.read_csv(\"Data\\TimeSeries1_Classification.csv\", index_col = 0)\n",
    "TS1_Class = TS1_Class.iloc[0:1280, 19:60]\n",
    "X_labels = np.array(TS1_Class).reshape(TS1_Class.size)\n",
    "\n",
    "SVM1 = svm.SVC(kernel=\"linear\")\n",
    "SVM2 = svm.SVC()\n",
    "\n",
    "#Cross validation and hyperparameter tuning\n",
    "cv = KFold(n_splits = 5, shuffle=True,  random_state = 123)\n",
    "sc = make_scorer(f1_score)\n",
    "SVMcv1=cross_validate(SVM1, X_train, X_labels, cv = cv, scoring=sc)\n",
    "SVMcv2=cross_validate(SVM2, X_train, X_labels, cv = cv, scoring=sc)\n",
    "print(np.mean(SVMcv1['test_score']),\n",
    "np.std(SVMcv1['test_score']))\n",
    "print(np.mean(SVMcv2['test_score']),\n",
    "np.std(SVMcv2['test_score']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "155419e57043e3c6c91350c5428c6cc33fefa50a0d623da8550d7adba7f4f47b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
